// services/QuestionsAnswers/uploadQuestionsAnswers.js
// Requires: npm install csv-parser validator
const path = require('path');
const fs = require('fs');
const csv = require('csv-parser');
const validator = require('validator');
const ensureKeyword = require('./ensureKeyword');
const { clearStopwordsCache } = require('../stopwords/loadStopwords');
const cleanupUnusedKeywords = require('./cleanupUnusedKeywords');

// ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å keyword ‡∏à‡∏≤‡∏Å string (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö , ; ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ)
function parseKeywords(str) {
	if (!str || typeof str !== 'string') return [];
	// ‡πÅ‡∏¢‡∏Å‡∏î‡πâ‡∏ß‡∏¢ comma, semicolon, ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ñ‡∏±‡πà‡∏ô‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô)
	return str
		.split(/[,;\n\r]+|\s{2,}/)
		.map(s => s.trim())
		.filter(s => s.length > 0);
}

// ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô normalize ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ dedupe keyword ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà/‡πÄ‡∏•‡πá‡∏Å ‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
function normalizeKeywordForMatch(s) {
	if (!s) return '';
	try {
		const noAccent = s.normalize('NFD').replace(/[\u0300-\u036f]/g, '');
		return noAccent.replace(/\s+/g, ' ').trim().toLowerCase();
	} catch (_) {
		return String(s).replace(/\s+/g, ' ').trim().toLowerCase();
	}
}

const uploadQuestionsAnswersService = (pool) => async (req, res) => {
	const notifyQuestionsAnswersUpdate = req.app.locals && req.app.locals.notifyQuestionsAnswersUpdate;
	// Debug
	console.log('[uploadQuestionsAnswers] headers:', {
		authorization: req.headers?.authorization,
		'content-type': req.headers?.['content-type'] || req.headers?.['Content-Type']
	});
	console.log('[uploadQuestionsAnswers] req.file:', req.file, 'req.files:', req.files);

	// If multer used upload.any(), pick first file
	if (!req.file && Array.isArray(req.files) && req.files.length > 0) {
		req.file = req.files[0];
		console.log('[uploadQuestionsAnswers] selected req.file from req.files:', req.file.fieldname, req.file.originalname);
	}

	// Fallback: accept CSV in body under file/csv/etc or raw text
	let createdTempFile = false;
	let tempFilePath = null;
	const bodyFileString = (typeof req.body === 'string' && req.body.length > 0)
		? req.body
		: (req.body && (req.body.file || req.body.csv || req.body.csvFile || req.body.data));

	if (!req.file && bodyFileString && typeof bodyFileString === 'string' && bodyFileString.length > 0) {
		try {
			const fileString = bodyFileString;
			let base64Data = fileString;
			const dataUrlMatch = fileString.match(/^data:(.+);base64,(.*)$/);
			let detectedMime = 'text/csv';
			if (dataUrlMatch) {
				detectedMime = dataUrlMatch[1] || 'text/csv';
				base64Data = dataUrlMatch[2];
			} else {
				const looksLikeBase64 = /^[A-Za-z0-9+/=\s]+$/.test(fileString.replace(/\r?\n/g,''));
				if (!looksLikeBase64) {
					base64Data = Buffer.from(fileString, 'utf8').toString('base64');
					detectedMime = 'text/csv';
				}
			}
			await fs.promises.mkdir(path.join(__dirname, '..', '..', 'uploads'), { recursive: true });
			const fileName = `upload_questionsanswers_${Date.now()}.csv`;
			tempFilePath = path.join(__dirname, '..', '..', 'uploads', fileName);
			const buffer = Buffer.from(base64Data, 'base64');
			await fs.promises.writeFile(tempFilePath, buffer);
			req.file = { path: tempFilePath, originalname: fileName, mimetype: detectedMime };
			createdTempFile = true;
			console.log('[uploadQuestionsAnswers] Created temp file from request body:', tempFilePath);
		} catch (err) {
			console.error('[uploadQuestionsAnswers] Failed to create temp file from body:', err);
		}
	}

	if (!req.file) {
		console.error('[uploadQuestionsAnswers] No file found. content-type:', req.headers['content-type']);
		return res.status(400).json({
			success: false,
			message: 'No file uploaded. Send multipart/form-data (file field) or raw CSV (Content-Type: text/csv).'
		});
	}

	const allowedMime = new Set(['text/csv', 'application/vnd.ms-excel', 'text/plain', 'application/csv']);
	const originalName = req.file.originalname || '';
	const extIsCsv = originalName.toLowerCase().endsWith('.csv');

	if (!allowedMime.has(req.file.mimetype) && !extIsCsv) {
		fs.promises.unlink(req.file.path).catch(()=>{});
		if (createdTempFile && tempFilePath) fs.promises.unlink(tempFilePath).catch(()=>{});
		return res.status(400).json({ success: false, message: `Invalid file type. Detected mimetype=${req.file.mimetype}` });
	}

	const filePath = req.file.path;
	const rows = [];
	let connection;
	const summary = { totalRows: 0, inserted: 0, updated: 0, failed: 0, deleted: 0, unassigned: 0 };

	// duplicates flags: allowDuplicates (upsert) and allowExactDuplicates (insert duplicates even when titles/texts match)
	const allowDuplicates = (String(req.body?.allowDuplicates || req.query?.allowDuplicates || '').toLowerCase() === 'true') || (req.body?.allowDuplicates === '1') || (req.query?.allowDuplicates === '1');
	let allowExactDuplicates = (String(req.body?.allowExactDuplicates || req.query?.allowExactDuplicates || '').toLowerCase() === 'true') || (req.body?.allowExactDuplicates === '1') || (req.query?.allowExactDuplicates === '1');
	const warnings = []; // non-fatal notices when duplicates-mode enabled

	// Default behavior: if no explicit flag provided and this is a file upload (multipart),
	// treat uploads as duplicates-allowed so users can import exact duplicate rows easily.
	try {
		const bodyHasFlag = !!(req.body && req.body.allowExactDuplicates && String(req.body.allowExactDuplicates).trim() !== '');
		const queryHasFlag = !!(req.query && req.query.allowExactDuplicates && String(req.query.allowExactDuplicates).trim() !== '');
		if (!bodyHasFlag && !queryHasFlag && req.file) {
			allowExactDuplicates = true;
			console.log('[uploadQuestionsAnswers] Defaulting allowExactDuplicates=true for multipart upload (no explicit flag)');
		}
	} catch (e) { /* ignore */ }

	console.log('[uploadQuestionsAnswers] allowDuplicates:', allowDuplicates, 'allowExactDuplicates:', allowExactDuplicates);

	try {
		// Read CSV
		await new Promise((resolve, reject) => {
			fs.createReadStream(filePath)
				.pipe(csv({ 
					bom: true, 
					mapHeaders: ({ header }) => header.trim().replace(/^\uFEFF/, '').replace(/^"|"$/g, '').trim()
				}))
				.on('data', data => rows.push(data))
				.on('end', resolve)
				.on('error', reject);
		});

		if (!rows || rows.length === 0) {
			try { await fs.promises.unlink(filePath); } catch(e){/*ignore*/ }
			return res.status(400).json({ success: false, message: 'CSV file empty or headers invalid.' });
		}

		// DEBUG: log headers and first row for diagnosis
		if (rows.length > 0) {
			console.log('[uploadQuestionsAnswers] CSV parsed headers:', Object.keys(rows[0]));
			console.log('[uploadQuestionsAnswers] First row sample:', rows[0]);
		}

		// NEW: Inspect CSV for keyword-like columns (CSV diagnostics only ‚Äî DB keyword handling is removed)
		try {
			const headerKeys = Object.keys(rows[0] || {}).map(k => String(k).trim());
			const candidateCols = ['KeywordText', 'Keywords', 'Keyword', 'KeywordsList'];
			const keywordCol = candidateCols.find(c => headerKeys.includes(c)) || null;
			if (keywordCol) {
				let nonEmpty = 0;
				let sample = '';
				for (const r of rows) {
					const v = r[keywordCol];
					if (v && String(v).trim().length > 0) {
						nonEmpty++;
						if (!sample) sample = String(v).trim().slice(0, 120);
					}
				}
				console.log(`[uploadQuestionsAnswers] CSV keyword column detected: "${keywordCol}" ‚Äî non-empty rows: ${nonEmpty}${sample ? `, sample="${sample}"` : ''}`);
			} else {
				console.log('[uploadQuestionsAnswers] CSV has no keyword column among: KeywordText, Keywords, Keyword, KeywordsList');
			}
		} catch (diagErr) {
			console.warn('[uploadQuestionsAnswers] CSV keyword diagnostics failed:', diagErr?.message || diagErr);
		}

		// Reorder: process rows that specify numeric QuestionsAnswersID first (ascending),
		// then the rows without an ID in original order ‚Äî this follows DB-specified IDs.
		try {
			const rowsWithId = [];
			const rowsWithoutId = [];
			for (const r of rows) {
				const idRaw = r.QuestionsAnswersID ? String(r.QuestionsAnswersID).trim() : '';
				if (/^\d+$/.test(idRaw)) rowsWithId.push(r);
				else rowsWithoutId.push(r);
			}
			rowsWithId.sort((a, b) => Number(a.QuestionsAnswersID) - Number(b.QuestionsAnswersID));
			// replace rows array with ordered rows
			rows.length = 0;
			rows.push(...rowsWithId, ...rowsWithoutId);
			console.log('[uploadQuestionsAnswers] Reordered rows: with-ID first (count:', rowsWithId.length, '), without-ID:', rowsWithoutId.length, ')');
		} catch (e) {
			console.warn('[uploadQuestionsAnswers] Could not reorder rows:', e.message || e);
		}

		// ------------------- new: detect exact duplicates within CSV and alert -------------------
		try {
			const trimVal = v => (v || '').toString().trim();
			const exactConflicts = [];

			for (let i = 0; i < rows.length; i++) {
				const aTitleRaw = trimVal(rows[i].QuestionTitle);
				const aTextRaw = trimVal(rows[i].QuestionText);
				if (!aTitleRaw && !aTextRaw) continue;

				for (let j = i + 1; j < rows.length; j++) {
					const bTitleRaw = trimVal(rows[j].QuestionTitle);
					const bTextRaw = trimVal(rows[j].QuestionText);

					if (aTitleRaw && bTitleRaw && aTitleRaw === bTitleRaw) {
						exactConflicts.push({
							type: 'exact-duplicate',
							field: 'QuestionTitle',
							rowA: i + 2,
							rowB: j + 2,
							value: aTitleRaw,
							description: `Exact duplicate in QuestionTitle at rows ${i + 2} and ${j + 2}: "${aTitleRaw}"`
						});
					}
					if (aTextRaw && bTextRaw && aTextRaw === bTextRaw) {
						exactConflicts.push({
							type: 'exact-duplicate',
							field: 'QuestionText',
							rowA: i + 2,
							rowB: j + 2,
							value: aTextRaw,
							description: `Exact duplicate in QuestionText at rows ${i + 2} and ${j + 2}: "${aTextRaw}"`
						});
					}
				}
			}

			if (exactConflicts.length > 0) {
				// If duplicates mode enabled, convert exact duplicates to warnings and continue; otherwise abort
				if (allowExactDuplicates || allowDuplicates) {
					warnings.push(...exactConflicts.map(c => ({ ...c, severity: 'warning' })));
					console.warn('[uploadQuestionsAnswers] Exact duplicates detected but duplicates-mode enabled; converting to warnings:', exactConflicts.length);
				} else {
					console.warn('[uploadQuestionsAnswers] Exact duplicate rows detected in CSV, aborting import. Conflicts:', exactConflicts);
					if (createdTempFile && tempFilePath) {
						fs.promises.unlink(tempFilePath).catch(()=>{});
					}
					return res.status(400).json({
						success: false,
						errorType: 'exact_duplicate',
						message: 'Exact duplicate rows detected in uploaded CSV. Please review the highlighted rows/columns before importing.',
						conflictsCount: exactConflicts.length,
						conflicts: exactConflicts
					});
				}
			}
		} catch (scanErr) {
			console.warn('[uploadQuestionsAnswers] exact-duplicate scan failed, continuing to fuzzy checks:', scanErr.message || scanErr);
		}
		// ------------------- end exact-duplicate block -------------------

		// ------------------- existing fuzzy similarity detection follows -------------------
		try {
			// normalize text: remove diacritics, punctuation, collapse whitespace
			const normalize = (s = '') => {
				const noAccent = s.normalize ? s.normalize('NFD').replace(/[\u0300-\u036f]/g, '') : s;
				return noAccent
					.replace(/[^\p{L}\p{N}\s]/gu, '') // remove punctuation
					.replace(/\s+/g, ' ')
					.trim()
					.toLowerCase();
			};

			// Levenshtein distance
			const levenshtein = (a = '', b = '') => {
				const m = a.length, n = b.length;
				if (m === 0) return n;
				if (n === 0) return m;
				const dp = Array.from({ length: m + 1 }, () => new Array(n + 1));
				for (let i = 0; i <= m; i++) dp[i][0] = i;
				for (let j = 0; j <= n; j++) dp[0][j] = j;
				for (let i = 1; i <= m; i++) {
					for (let j = 1; j <= n; j++) {
						const cost = a[i - 1] === b[j - 1] ? 0 : 1;
						dp[i][j] = Math.min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost);
					}
				}
				return dp[m][n];
			};

			const alerts = [];
			const threshold = 0.8; // similarity threshold

			for (let i = 0; i < rows.length; i++) {
				const aTitle = normalize(rows[i].QuestionTitle || '');
				const aText = normalize(rows[i].QuestionText || '');
				// skip empty normalized fields
				if (!aTitle && !aText) continue;

				for (let j = i + 1; j < rows.length; j++) {
					const bTitle = normalize(rows[j].QuestionTitle || '');
					const bText = normalize(rows[j].QuestionText || '');
					if (!bTitle && !bText) continue;

					// check title similarity
					if (aTitle && bTitle) {
						const maxLen = Math.max(aTitle.length, bTitle.length) || 1;
						const dist = levenshtein(aTitle, bTitle);
						const sim = 1 - (dist / maxLen);
						// substring strong match also counts
						const substringMatch = aTitle.includes(bTitle) || bTitle.includes(aTitle);

						// skip alert when strings are identical after removing all digits (treat "text1" vs "text2" as distinct if you WANT
						// to ignore numeric-only differences; here we *skip* alert when they only differ by digits)
						const stripDigits = s => (s || '').replace(/\p{N}+/gu, '').trim();
						if (stripDigits(aTitle) === stripDigits(bTitle)) {
							// they differ only by digits (or are identical after removing digits) -> treat as non-duplicate, skip
						} else if (sim >= threshold || substringMatch) {
							alerts.push({
								type: 'title-similar',
								rowA: i + 2,
								rowB: j + 2,
								field: 'QuestionTitle',
								valueA: rows[i].QuestionTitle,
								valueB: rows[j].QuestionTitle,
								similarity: +(sim.toFixed(3)),
								substringMatch: !!substringMatch
							});
							continue;
						}
					}

					// check text similarity
					if (aText && bText) {
						const maxLen = Math.max(aText.length, bText.length) || 1;
						const dist = levenshtein(aText, bText);
						const sim = 1 - (dist / maxLen);
						const substringMatch = aText.includes(bText) || bText.includes(aText);

						// same digit-stripping logic for QuestionText
						const stripDigits = s => (s || '').replace(/\p{N}+/gu, '').trim();
						if (stripDigits(aText) === stripDigits(bText)) {
							// differ only by digits -> skip
						} else if (sim >= threshold || substringMatch) {
							alerts.push({
								type: 'text-similar',
								rowA: i + 2,
								rowB: j + 2,
								field: 'QuestionText',
								valueA: rows[i].QuestionText,
								valueB: rows[j].QuestionText,
								similarity: +(sim.toFixed(3)),
								substringMatch: !!substringMatch
							});
						}
					}
				}
			}

			if (alerts.length > 0) {
				// Build human-friendly descriptions for each alert
				const conflicts = alerts.map(a => {
					const desc = a.type === 'title-similar'
						? `Row ${a.rowA} and Row ${a.rowB} have similar QuestionTitle: "${a.valueA}" <> "${a.valueB}" (similarity=${a.similarity}${a.substringMatch ? ', substring match' : ''})`
						: `Row ${a.rowA} and Row ${a.rowB} have similar QuestionText: "${a.valueA}" <> "${a.valueB}" (similarity=${a.similarity}${a.substringMatch ? ', substring match' : ''})`;
					return {
						...a,
						description: desc
					};
				});

				// If duplicates-mode enabled, convert these to warnings and continue; otherwise abort and return detailed conflict UI
				if (allowExactDuplicates || allowDuplicates) {
					warnings.push(...conflicts.map(c => ({ ...c, severity: 'warning' })));
					console.warn('[uploadQuestionsAnswers] Similar rows detected but duplicates-mode enabled; converted to warnings, continuing import. Conflicts:', conflicts.length);
				} else {
					console.warn('[uploadQuestionsAnswers] Similar rows detected in CSV, aborting import. Conflicts:', conflicts);
					// cleanup temp file if created
					if (createdTempFile && tempFilePath) {
						fs.promises.unlink(tempFilePath).catch(()=>{});
					}

					// Attach rowsDetail to each conflict for UI highlighting
					const conflictsWithDetails = conflicts.map(a => {
						const rowA = rows[a.rowA - 2] || {}; // convert back to zero-based index used earlier
						const rowB = rows[a.rowB - 2] || {};
						return {
							...a,
							rowsDetail: [
								{ rowNum: a.rowA, QuestionTitle: rowA.QuestionTitle, QuestionText: rowA.QuestionText, CategoriesID: rowA.CategoriesID },
								{ rowNum: a.rowB, QuestionTitle: rowB.QuestionTitle, QuestionText: rowB.QuestionText, CategoriesID: rowB.CategoriesID }
							]
						};
					});

					// Build UI hint (large modal) for frontend
					const highlightRows = Array.from(new Set(conflictsWithDetails.flatMap(c => (c.rows || [])))).sort((a,b)=>a-b);

					// Return structured, detailed response
					return res.status(400).json({
						success: false,
						errorType: 'duplicate_data',
						message: '‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏ñ‡∏ß/‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤',
						message_th: '‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏ñ‡∏ß/‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤',
						message_en: 'Duplicate or very similar rows detected in uploaded CSV. Please review the highlighted rows/columns before importing.',
						conflictsCount: conflictsWithDetails.length,
						conflicts: conflictsWithDetails,
						ui: {
							title: '‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: ‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥/‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢',
							description: '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤',
							size: 'large',
							severity: 'error',
							highlightRows
						}
					});
				}
			}
		} catch (scanErr) {
			console.warn('[uploadQuestionsAnswers] similarity scan failed, continuing import:', scanErr.message || scanErr);
			// fallback: continue processing if scanner fails
		}
		// ------------------- end fuzzy block -------------------

		summary.totalRows = rows.length;

		connection = await pool.getConnection();
		await connection.beginTransaction();

		const uploaderId = (req.user?.userId ?? req.user?.officerId);
		if (!uploaderId) {
			await connection.release();
			return res.status(401).json({ success: false, message: 'Unauthorized: uploader not identified from token.' });
		}

		// Determine OfficerID to use for inserted QAs: if uploader is an Officer use their ID, otherwise set NULL for Admins
		const ownerOfficerId = (req.user && req.user.usertype === 'Officer') ? uploaderId : null;

		// Attempt to determine a numeric next ID in case QuestionsAnswersID is NOT auto-increment.
		// This will be used when CSV rows do not provide an ID but the DB requires one.
		let nextQaId = null;
		try {
			const [maxRows] = await connection.query('SELECT MAX(QuestionsAnswersID) AS maxId FROM QuestionsAnswers');
			const maxId = (maxRows && maxRows[0] && maxRows[0].maxId) ? Number(maxRows[0].maxId) : 0;
			nextQaId = maxId + 1;
		} catch (e) {
			// If table missing or query fails, fall back to timestamp-based numeric ids
			nextQaId = Math.floor(Date.now() / 1000);
			console.warn('[uploadQuestionsAnswers] Could not determine max QuestionsAnswersID, using fallback nextQaId:', nextQaId, e.message || e);
		}

		// track QuestionsAnswers IDs we inserted/updated from CSV
		const processedQaIds = new Set();
		for (let i = 0; i < rows.length; i++) {
			try {
				const r = rows[i];

				// Helper: get field value from multiple possible header names (case-insensitive + Thai aliases)
				const getField = (obj, names) => {
					// Normalize target names for matching
					const normNames = names.map(n => n.toLowerCase().replace(/\s+/g, ''));
					for (const [key, val] of Object.entries(obj)) {
						const normKey = key.toLowerCase().replace(/\s+/g, '');
						if (normNames.includes(normKey) && typeof val !== 'undefined' && String(val).trim().length > 0) {
							return String(val).trim();
						}
					}
					return '';
				};

				const rowNum = i + 2; // CSV header row considered row 1
				const QuestionsAnswersIDraw = getField(r, ['QuestionsAnswersID','questionsanswersid','ID','Id']);
				const QuestionTitle = getField(r, ['QuestionTitle','questiontitle','QUESTIONTITLE','‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠','‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°','Question']);
				const QuestionText = getField(r, ['QuestionText','questiontext','QUESTIONTEXT','‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö','‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î','Answer','Text']);
				const ReviewDateRaw = getField(r, ['ReviewDate','reviewdate','REVIEWDATE','‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô','Review']);
				let CategoriesID = getField(r, ['CategoriesID','categoriesid','CATEGORYID','CategoryID','‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà','Categories','Category']);

				// ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÜ (‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡πà‡∏≤‡∏á) ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô error
				const isCompletelyEmptyRow = Object.values(r).every(v => String(v ?? '').trim() === '');
				if (isCompletelyEmptyRow) {
					console.log(`[uploadQuestionsAnswers] Skipping empty row ${rowNum}`);
					summary.totalRows--; // ‡πÑ‡∏°‡πà‡∏ô‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
					continue;
				}

				// üÜï Clean Excel formula format: ="1-1" ‚Üí 1-1, ="1" ‚Üí 1
				// Excel sometimes exports as ="value" to preserve text format
				if (CategoriesID) {
					// Remove ="..." wrapper
					const excelFormulaMatch = CategoriesID.match(/^="?([^"]*)"?$/);
					if (excelFormulaMatch) {
						CategoriesID = excelFormulaMatch[1];
						console.log(`[uploadQuestionsAnswers] row ${rowNum}: Cleaned CategoriesID from Excel formula format: "${r.CategoriesID}" ‚Üí "${CategoriesID}"`);
					}
				}

				// validation
				if (!QuestionTitle) throw new Error(`Error on row ${rowNum}: QuestionTitle is required.`);
				if (!QuestionText) throw new Error(`Error on row ${rowNum}: QuestionText is required.`);

				// ReviewDate must not be NULL in DB ‚Äî use provided date or default to today
				const toIsoDate = (d) => {
					if (!d) return null;
					// Support dd/mm/yy or dd/mm/yyyy from Excel exports
					const m = d.match(/^([0-3]?\d)\/(1[0-2]|0?[1-9])\/((?:\d{2})|(?:\d{4}))$/);
					if (m) {
						let day = parseInt(m[1], 10);
						let month = parseInt(m[2], 10);
						let year = m[3].length === 2 ? 2000 + parseInt(m[3], 10) : parseInt(m[3], 10);
						const mm = String(month).padStart(2, '0');
						const dd = String(day).padStart(2, '0');
						return `${year}-${mm}-${dd}`;
					}
					// Fallback to Date parser
					try {
						const dt = new Date(d);
						if (!isNaN(dt)) return dt.toISOString().slice(0,10);
					} catch(e){}
					return null;
				};
								// Normalize CategoriesID when Excel auto-formats to Thai month names (e.g., 1-‡∏°.‡∏Ñ.)
								if (CategoriesID) {
									const thaiMonths = {
										'‡∏°.‡∏Ñ.': '1', '‡∏Å.‡∏û.': '2', '‡∏°‡∏µ.‡∏Ñ.': '3', '‡πÄ‡∏°.‡∏¢.': '4', '‡∏û.‡∏Ñ.': '5', '‡∏°‡∏¥.‡∏¢.': '6',
										'‡∏Å.‡∏Ñ.': '7', '‡∏™.‡∏Ñ.': '8', '‡∏Å.‡∏¢.': '9', '‡∏ï.‡∏Ñ.': '10', '‡∏û.‡∏¢.': '11', '‡∏ò.‡∏Ñ.': '12'
									};
									const monthMatch = CategoriesID.match(/^(\d+)\-([‡∏Å-‡πô\.]+)$/);
									if (monthMatch && thaiMonths[monthMatch[2]]) {
										CategoriesID = `${monthMatch[1]}-${thaiMonths[monthMatch[2]]}`;
									}
								}
				let ReviewDate = toIsoDate(ReviewDateRaw);
				if (!ReviewDate) {
					ReviewDate = new Date().toISOString().slice(0,10);
					console.log(`[uploadQuestionsAnswers] row ${rowNum}: ReviewDate missing/invalid, set to ${ReviewDate}`);
				}

				// Decide insert vs update
				let qaId = null;
				// Helper: find existing QA by title or text
				const findByTitleOrText = async (title, text) => {
					try {
						const [found] = await connection.query(
							'SELECT QuestionsAnswersID FROM QuestionsAnswers WHERE QuestionTitle = ? OR QuestionText = ? LIMIT 1',
							[title, text]
						);
						return (found && found.length > 0) ? found[0].QuestionsAnswersID : null;
					} catch (e) {
						return null;
					}
				};

				if (QuestionsAnswersIDraw && /^\d+$/.test(QuestionsAnswersIDraw)) {
					const providedId = Number(QuestionsAnswersIDraw);
					// If the provided ID exists, update it
					const [existsById] = await connection.query(
						'SELECT QuestionsAnswersID FROM QuestionsAnswers WHERE QuestionsAnswersID = ? LIMIT 1',
						[providedId]
					);
					if (existsById && existsById.length > 0) {
						qaId = providedId;
						await connection.query(
							'UPDATE QuestionsAnswers SET ReviewDate = ?, QuestionTitle = ?, QuestionText = ?, CategoriesID = ?, OfficerID = ? WHERE QuestionsAnswersID = ?',
					[ReviewDate, QuestionTitle, QuestionText, CategoriesID, ownerOfficerId, qaId]
						);
						summary.updated++;
					} else {
						// If not by ID, check duplicates by title/text and overwrite those
						const dupId = await findByTitleOrText(QuestionTitle, QuestionText);
						if (dupId) {
							qaId = dupId;
							await connection.query(
								'UPDATE QuestionsAnswers SET ReviewDate = ?, QuestionTitle = ?, QuestionText = ?, CategoriesID = ?, OfficerID = ? WHERE QuestionsAnswersID = ?',
								[ReviewDate, QuestionTitle, QuestionText, CategoriesID, uploaderId, qaId]
							);
							summary.updated++;
						} else {
							// Safe to insert with provided ID
							await connection.query(
								'INSERT INTO QuestionsAnswers (QuestionsAnswersID, ReviewDate, QuestionTitle, QuestionText, CategoriesID, OfficerID) VALUES (?, ?, ?, ?, ?, ?)',
						[providedId, ReviewDate, QuestionTitle, QuestionText, CategoriesID, ownerOfficerId]
							);
							qaId = providedId;
							summary.inserted++;
							if (typeof nextQaId === 'number' && providedId >= nextQaId) nextQaId = providedId + 1;
						}
					}
				} else {
					// No provided ID: check duplicate by title/text first and update if found
					const dupId = await findByTitleOrText(QuestionTitle, QuestionText);
					if (dupId) {
						qaId = dupId;
						await connection.query(
							'UPDATE QuestionsAnswers SET ReviewDate = ?, QuestionTitle = ?, QuestionText = ?, CategoriesID = ?, OfficerID = ? WHERE QuestionsAnswersID = ?',
						[ReviewDate, QuestionTitle, QuestionText, CategoriesID, ownerOfficerId, qaId]
						);
						summary.updated++;
					} else {
						// Insert new record using generated ID (if DB requires explicit ID)
						const genId = nextQaId;
						nextQaId = (typeof nextQaId === 'number') ? nextQaId + 1 : genId + 1;
						await connection.query(
							'INSERT INTO QuestionsAnswers (QuestionsAnswersID, ReviewDate, QuestionTitle, QuestionText, CategoriesID, OfficerID) VALUES (?, ?, ?, ?, ?, ?)',
						[genId, ReviewDate, QuestionTitle, QuestionText, CategoriesID, ownerOfficerId]
						);
						qaId = genId;
						summary.inserted++;
					}
				}

				// record processed QA id (string) for later cleanup
				try { processedQaIds.add(String(qaId)); } catch(e){/*ignore*/}

				// NEW: keywords handling (always ensure keywords exist in DB, then map)
			// Reconstruct keywords across adjacent columns when CSV fields are not quoted and commas split into extra columns (_4, _5, ...)
			let keywordsParts = [];
			const kwMain = r.KeywordText || r.Keywords || r.Keyword || r.KeywordsList || '';
			if (kwMain && String(kwMain).trim() !== '') keywordsParts.push(String(kwMain).trim());
			for (const [k, v] of Object.entries(r)) {
				if (/^_\d+$/.test(k) && v && String(v).trim() !== '') keywordsParts.push(String(v).trim());
			}
			const keywordsString = keywordsParts.join(',');
			const kws = parseKeywords(keywordsString);
			// dedupe ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÅ‡∏ö‡∏ö case/space-insensitive ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£ insert ‡∏ã‡πâ‡∏≥
			const seenKw = new Set();
			const uniqueKws = [];
			for (const kw of kws) {
				const norm = normalizeKeywordForMatch(kw);
				if (!norm || seenKw.has(norm)) continue;
				seenKw.add(norm);
				uniqueKws.push(kw);
			}

				// delete existing mappings for this QA, then recreate
				try { await connection.query('DELETE FROM AnswersKeywords WHERE QuestionsAnswersID = ?', [qaId]); } catch (_) {}

				for (const kw of uniqueKws) {
					try {
					const { keywordId, created } = await ensureKeyword(connection, kw, uploaderId);
					if (keywordId) {
						console.log('[uploadQuestionsAnswers] Inserting AnswersKeywords mapping:', qaId, { keywordId, created });
						try {
							await connection.query(
								'INSERT INTO AnswersKeywords (QuestionsAnswersID, KeywordID) VALUES (?, ?)',
								[qaId, keywordId]
							);
						} catch (e) { console.warn('[uploadQuestionsAnswers] Insert AnswersKeywords failed:', e && e.message ? e.message : e); }
					}
				} catch (e) {
					console.warn('[uploadQuestionsAnswers] ensureKeyword failed for', kw, e && e.message ? e.message : e);
				}
				}
				// These will run in background after commit
			} catch (rowErr) {
				console.error(`[uploadQuestionsAnswers] Row ${i + 2} failed:`, rowErr.message || rowErr);
				// If a row failed to insert/update, still attempt to ensure keywords from the CSV exist in Keywords table
				try {
					const rowObj = rows[i] || {};
				// Reconstruct keywords across adjacent _N columns if CSV didn't quote fields properly
				let kwParts = [];
				const kwMain2 = rowObj.KeywordText || rowObj.Keywords || rowObj.Keyword || rowObj.KeywordsList || '';
				if (kwMain2 && String(kwMain2).trim() !== '') kwParts.push(String(kwMain2).trim());
				for (const [k, v] of Object.entries(rowObj)) {
					if (/^_\d+$/.test(k) && v && String(v).trim() !== '') kwParts.push(String(v).trim());
				}
				const kws = parseKeywords(kwParts.join(',') || '');
					const seenKw = new Set();
					let createdKws = 0;
					for (const kw of kws) {
						const norm = normalizeKeywordForMatch(kw);
						if (!norm || seenKw.has(norm)) continue;
						seenKw.add(norm);
						try {
							const { keywordId } = await ensureKeyword(connection, kw, uploaderId);
							if (keywordId) createdKws++;
						} catch (e) {
							// ignore individual keyword errors
						}
					}
					if (createdKws > 0) {
						warnings.push({ type: 'keywords-created', row: i + 2, created: createdKws, message: 'Keywords created for failed row' });
						console.log('[uploadQuestionsAnswers] Created', createdKws, 'keywords for failed row', i + 2);
					}
				} catch (kwErr) {
					console.warn('[uploadQuestionsAnswers] Keyword creation for failed row failed:', kwErr && kwErr.message ? kwErr.message : kwErr);
				}
				summary.failed++;
				continue;
			}
		}

		// Remove QuestionsAnswers for this uploader that are NOT present in the uploaded CSV
		try {
			console.log('[uploadQuestionsAnswers] Checking for QAs to delete...');
			console.log('[uploadQuestionsAnswers] uploaderId:', uploaderId);
			console.log('[uploadQuestionsAnswers] processedQaIds:', [...processedQaIds]);
			
			const [existingRows] = await connection.query('SELECT QuestionsAnswersID FROM QuestionsAnswers WHERE OfficerID = ?', [uploaderId]);
			const existingIds = (existingRows || []).map(r => String(r.QuestionsAnswersID));
			console.log('[uploadQuestionsAnswers] existingIds for this officer:', existingIds);
			
			const toRemove = existingIds.filter(id => !processedQaIds.has(id));
			console.log('[uploadQuestionsAnswers] toRemove:', toRemove);
			
			if (toRemove.length > 0) {
				try {
					// Get ChatLogIDs that reference these QAs
					const [chatLogs] = await connection.query(
						'SELECT ChatLogID FROM ChatLogHasAnswers WHERE QuestionsAnswersID IN (?)', 
						[toRemove]
					);
					const chatLogIds = chatLogs.map(r => r.ChatLogID);
					
					// 1. Delete feedbacks that reference these chat logs (FK: feedbacks ‚Üí chatloghasanswers)
					if (chatLogIds.length > 0) {
						await connection.query('DELETE FROM Feedbacks WHERE ChatLogID IN (?)', [chatLogIds]);
						console.log('[uploadQuestionsAnswers] Deleted Feedbacks for', chatLogIds.length, 'chat logs');
					}
					
					// 2. Delete chat log references (FK: chatloghasanswers ‚Üí questionsanswers)
					await connection.query('DELETE FROM ChatLogHasAnswers WHERE QuestionsAnswersID IN (?)', [toRemove]);
					console.log('[uploadQuestionsAnswers] Deleted ChatLogHasAnswers references');
					
					// 3. Delete keyword mappings
					await connection.query('DELETE FROM AnswersKeywords WHERE QuestionsAnswersID IN (?)', [toRemove]);
					console.log('[uploadQuestionsAnswers] Deleted AnswersKeywords');
					
					// 4. Now delete QA rows
					const [delRes] = await connection.query('DELETE FROM QuestionsAnswers WHERE QuestionsAnswersID IN (?)', [toRemove]);
					summary.deleted = typeof delRes.affectedRows === 'number' ? delRes.affectedRows : toRemove.length;
					summary.unassigned = 0;
					console.log('[uploadQuestionsAnswers] Deleted', summary.deleted, 'QA rows');
				} catch (delErr) {
					console.error('[uploadQuestionsAnswers] delete failed:', delErr.message || delErr);
					summary.deleted = 0;
					summary.unassigned = 0;
				}
			}
		} catch (cleanupErr) {
			console.warn('[uploadQuestionsAnswers] cleanup of existing QuestionsAnswers failed:', cleanupErr.message || cleanupErr);
		}

		// üÜï Clean up orphaned keywords before commit
		try {
			if (req.file) {
				// If this was a file upload, do not purge orphaned keywords created during import ‚Äî
				// users expect keywords from CSV to persist even if QA rows failed to insert.
				console.log('[uploadQuestionsAnswers] Skipping orphaned keywords cleanup for file upload to preserve user-provided keywords');
			} else {
				const cleanupResult = await cleanupUnusedKeywords(connection);
				if (cleanupResult.deletedCount > 0) {
					console.log(`üßπ Cleaned up ${cleanupResult.deletedCount} orphaned keywords after upload`);
				}
			}
		} catch (cleanupErr) {
			console.warn('[uploadQuestionsAnswers] keyword cleanup failed (non-fatal):', cleanupErr.message || cleanupErr);
		}

		// commit all changes (inserts/updates and deletions) as one transaction
		await connection.commit();

		// archive uploaded file: clear target dir then copy
		try {
			if (uploaderId) {
				const targetDir = path.join(__dirname, '..', '..', 'files', 'managequestionsanswers', String(uploaderId));
				await fs.promises.mkdir(targetDir, { recursive: true });

				// clear existing files in targetDir
				try {
					const entries = await fs.promises.readdir(targetDir);
					for (const entry of entries) {
						const entryPath = path.join(targetDir, entry);
						await fs.promises.rm(entryPath, { recursive: true, force: true }).catch(()=>{});
					}
				} catch(e){/* ignore */ }

				const timestamp = new Date().toISOString().replace(/[-:.TZ]/g, '').slice(0, 14);
				const targetFile = path.join(targetDir, `questionsanswers_${timestamp}.csv`);
				await fs.promises.copyFile(filePath, targetFile);
			}
		} catch (copyErr) {
			console.error('[uploadQuestionsAnswers] Failed to archive uploaded file:', copyErr);
		}

		// ‡∏õ‡∏•‡πà‡∏≠‡∏¢ connection ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
		try { await connection.release(); } catch (e) { /* ignore */ }

		// üîÑ Auto-export CSV after successful upload
		try {
			const { autoExportQuestionsAnswersCSV } = require('./autoExportCSV');
			await autoExportQuestionsAnswersCSV(pool, uploaderId);
			console.log('‚úÖ Auto-exported CSV after upload');
		} catch (exportErr) {
			console.error('‚ö†Ô∏è  Auto-export failed (non-fatal):', exportErr);
			// Don't fail the request if export fails
		}

				// Broadcast realtime update to /ws/questions-answers
				if (notifyQuestionsAnswersUpdate) {
					notifyQuestionsAnswersUpdate({ action: 'uploaded', summary });
				}

				// Clear stopwords cache when keywords may have been added
				clearStopwordsCache();

				const response = { success: true, summary };
				if (warnings && warnings.length > 0) response.warnings = warnings;
				if (allowDuplicates || allowExactDuplicates) {
					response.message = '‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß (‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ã‡πâ‡∏≥ ‚Äî ‡∏ö‡∏≤‡∏á‡πÅ‡∏ñ‡∏ß‡∏ñ‡∏π‡∏Å‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô)';
					response.message_th = response.message;
					response.message_en = 'Upload completed (duplicates allowed ‚Äî some rows are flagged as warnings).';
				}
				res.json(response);
	} catch (err) {
		console.error('[uploadQuestionsAnswers] Unexpected error:', err);
		if (connection) {
			try { await connection.rollback(); } catch(e){}
			finally { await connection.release(); }
		}
		res.status(500).json({
			success: false,
			message: 'Internal server error.',
			error: err.message || String(err)
		});
	} finally {
		if (createdTempFile && tempFilePath) {
			fs.promises.unlink(tempFilePath).catch(()=>{});
		}
		// remove uploaded temp (multer) file if still present
		try { await fs.promises.access(filePath); await fs.promises.unlink(filePath); } catch(e) { /* ignore */ }
	};
};

module.exports = uploadQuestionsAnswersService;
